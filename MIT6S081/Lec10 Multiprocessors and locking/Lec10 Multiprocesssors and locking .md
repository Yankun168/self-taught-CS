# Lec 10: Multiprocessors and locking

## 为什么需要锁？

现在的操作系统一般拥有多个CPU并行处理，这样能提高操作系统的效率。 如果一个应用程序运行在多个CPU上，多个CPU可能会并行的访问共享的数据资源。可能一个CPU在读入数据，另外一个CPU在写入数据，这时我们需要使用锁来协调对于共享数据的更新，保证数据的一致性。

原本我们希望使用并行来提高CPU的效率，然而锁会使得操作系统串行处理，限制了CPU的性能。出于正确性，我们需要使用锁，然而锁又会限制CPU的性能。接下来我们需要看看如何改善这个处境。



**回到最开始，为什么程序一定要使用多个CPU核来提高性能？**

下图介绍了处理器过去三十五年的发展。

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)

可以看到，绿线代表CPU的时钟频率，在2000后没有再增加过了。这限制了单CPU的性能（蓝线）不再增长。 但另一方面，深红色线CPU中晶体管的数量在增加。因此，单核已经无法使CPU更快了，我们必须增加处理器上核的数量（黑线）。

那为什么要用锁？ 保证程序的正确性。当同一份数据被同时读写时会出现race condition。 

接下来我们会创建一个race condition，然后看看它是什么样的。

kalloc.c中的kfree函数会将释放的page保存在freelist中。

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)

freelist是一个链表，保存着所有可用的物理page。 当函数中，可用看到有一个锁kmem.lock， 当我们要更新freelist时，我们必须先加上锁，更新完成后再释放掉。这样这段上锁的区间就是原子执行。

而如果我们注释这段上锁和释放锁的代码后，freelist就不受保护，可能会出现很严重的数据错误。

## 介绍一下锁

在xv6中，锁是一个对象，是一个结构体，包含了一些字段来维护锁的状态，锁有非常直观的API：

- acquire：接受一个锁指针，acquire保证在同一时间只有一个进程会成功获取锁。
- release：接受一个lock指针。

在acquire和release之间的代码称为critical section。

现在的程序通常有很多锁。 锁会序列化代码的执行。如果两个cpu想要同时进入到同一个critical section中，只有一个能成功进入，另外一个会在第一个退出后再进入。 

如果内核中有一把大锁，big kernel lock。基本上所有的sys call 都会被这把大锁保护而序列化。系统调用会按照这样的流程处理： 一个系统调用获取到了big kernel lock后，完成自己的操作，之后释放big kernel lock，返回到用户空间，之后下一个sys call才能调用。 如果我们只有一把锁，那么并行处理的程序都会变成串行执行。 因此操作系统一般有多把锁，这样实现了一定程度的并发执行。比如说，两个sys call使用了不同类型的锁，它们之间可以并发进行。

有几点需要特别注意，并没有强制一定要使用锁。这完全由程序员自己决定，如果你需要一段代码具有原子性，那就要加锁。

其次，代码不会自动加锁，程序员自己要确定好是否将锁与数据结构关联，并在适当的位置增加锁的acquire和release。

## 什么时候使用锁？

一个简单的原则是，两个进程同时访问了共享的数据结构，并且其中一个会更新该数据结构，那么就需要对这个数据结构加锁了。

这条规则在某种程度上说过于严格了。在一些场合不加锁也能正常工作。 不加锁的程序称为 lock-free program。不加锁的目的是为了更好的性能。然而这样极大的增加了程序的复杂度。这节课的大部分时间我们还是会考虑如何使用锁来控制共享的数据，因为这已经足够复杂了，很多时候就算直接使用锁也不是那么的直观。

在其他情况，虽然不涉及到访问共享数据，但我们同样需要保证序列性。 比如说printf希望打印连续的字符序列，而不希望被其他进程打断。

那我们能通过自动创建锁来避免race condition吗？ 这样有些严格并且还可能造成错误。

比如说我们调用sys call rename这个调用会将文件从一个目录移到另一个目录，我们现在将文件d1/x移到文件d2/y。

按照之前的说法，我们进行以下步骤

```
lock1 d1/x

delete d1/x

release lock1 

lock2 d2/y

add d2/y

release lock2
```

如果按这个步骤进行，当删除完d1/x后，其他进程就会发现d1/x不存在了，这是错误的结果，因为文件还在，只是被重命名为d2/y。

因此，我们需要在最开始就对d1，d2加锁。最后再释放。

在这个例子中，我们的操作需要涉及到多个锁，但是直接为每个对象自动分配一个锁会带来错误的结果。在这个例子中，锁应该与操作而不是数据关联，所以自动加锁在某些场景下会出问题。

> 学生提问：可不可以在访问某个数据结构的时候，就获取所有相关联的数据结构的锁？ 
>
> Frans教授：这是一种实现方式。但是这种方式最后会很快演进成big kernel lock，这样你就失去了并发执行的能力，但是你肯定想做得更好。这里就是使用锁的矛盾点了，如果你想要程序简单点，可以通过coarse-grain locking（注，也就是大锁），但是这时你就失去了性能。

## 锁的特性和死锁

锁有三个特性：

1. 避免丢失更新。 比如说在kfree函数中，我们如果没加锁，对freelist更新就会丢失。

2. 锁可以打包多个操作，使他们具有原子性。
3. 锁可以维护数据结构的不变性。

锁能够保证程序的正确性，但同时不正确的使用锁会带来死锁问题。

比如说，当你acquire一个锁，进入到critical section，再acquire同一个锁；第二个acquire必须要等到第一个acquire状态被release了才能继续执行，但是不继续执行的话又走不到第一个release，所以程序就一直卡在这了。这就是一个死锁。

这是最简单的情况，xv6会检测这样的死锁，如果检测到会触发一个panic。

另外一种更复杂的情况就很难被检测出来。

当有多个锁的时候，场景会更加有趣。假设现在我们有两个CPU，一个是CPU1，另一个是CPU2。CPU1执行rename将文件d1/x移到d2/y，CPU2执行rename将文件d2/a移到d1/b。这里CPU1将文件从d1移到d2，CPU2正好相反将文件从d2移到d1。我们假设我们按照参数的顺序来acquire锁，那么CPU1会先获取d1的锁，如果程序是真正的并行运行，CPU2同时也会获取d2的锁。之后CPU1需要获取d2的锁，这里不能成功，因为CPU2现在持有锁，所以CPU1会停在这个位置等待d2的锁释放。而另一个CPU2，接下来会获取d1的锁，它也不能成功，因为CPU1现在持有锁。这也是死锁的一个例子，有时候这种场景也被称为deadly embrace。这里的死锁就没那么容易探测了。

这里的解决方法是对锁进行排序。所有的操作都必须以相同的顺序获取锁。

对于一个系统设计者，你需要确定所有的锁对象的全局顺序。 例如，在这个例子中d1的优先级大于d2，那么就先获取d1的锁。

如果这样做的话，会违背代码抽象的原则。 一个函数f在调用另一个函数g的时候，就必须知道g中有什么样的锁，才能对所有的锁做一些全局锁的排序。

然而代码抽象希望f不知道g的任何细节。但是不幸的是，具体实现中，m2内部的锁需要泄露给m1，这样m1才能完成全局锁排序。所以当你设计一些更大的系统时，锁使得代码的模块化更加的复杂了。

## 锁与性能

上一节我们提到，锁会造成两个问题，一是死锁，二是破坏程序的模块化。这一节介绍锁对性能的影响。

之前已经反复提到过，锁会减低代码的并行度，影响代码的性能。

基本来说，如果你要更高的性能就需要拆分数据结构和锁。 如果你只有一个big kernel block，那么程序就是序列化运行，只能被一个cpu执行。

如果你需要性能随着cpu的数量增加而增加，就需要拆分数据结构和锁。

那怎么拆分呢？通常不会很简单，有的时候还有些困难。比如说，你是否应该为每个目录关联不同的锁？你是否应该为每个inode关联不同的锁？你是否应该为每个进程关联不同的锁？或者是否有更好的方式来拆分数据结构呢？如果你重新设计了加锁的规则，你需要确保不破坏内核一直尝试维护的数据不变性。

如果你对锁进行拆分，可能需要重写代码，引入更多的锁来维持数据的正确性。

所以这里就有矛盾点了。我们想要获得更好的性能，那么我们需要有更多的锁，但是这又引入了大量的工作。

通常来说，开发的流程是：

1. 以coarse-grained lock开始。（程序整体序列化运行）
2. 对程序进行测试是否能使用多核。
3. 如果可以，那么工作就结束了，你对于锁的设计足够话。
4. 如果不行，那么存在锁之间的竞争，多个进程尝试获取同一个锁，它们将序列化的执行，性能无法提高，你需要承购程序。

在这个流程中，测试的过程比较重要。有可能模块使用了coarse-grained  lock，但是它并没有经常被并行的调用，那么其实就没有必要重构程序，因为重构程序设计到大量的工作，并且也会使得代码变得复杂。所以如果不是必要的话，还是不要进行重构。

## XV6中UART模块对于锁的使用

接下来我们看一下XV6的代码，通过代码来理解锁是如何在XV6中工作的。我们首先查看一下uart.c，在上节课介绍中断的时候我们提到了这里的锁，现在我们具体的来看一下。因为现在我们对锁更加的了解了，接下来将展示一些更有趣的细节。

从代码上看UART只有一个锁。

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)

所以你可以认为对于UART模块来说，现在是一个coarse-grained lock的设计。这个锁保护了UART的的传输缓存；写指针；读指针。当我们传输数据时，写指针会指向传输缓存的下一个空闲槽位，而读指针指向的是下一个需要被传输的槽位。这是我们对于并行运算的一个标准设计，它叫做消费者-生产者模式。

所以现在有了一个缓存，一个写指针和一个读指针。读指针的内容需要被显示，写指针接收来自例如printf的数据。我们前面已经了解到了锁有多个角色。第一个是保护数据结构的特性不变，数据结构有一些不变的特性，例如读指针需要追赶写指针；从读指针到写指针之间的数据是需要被发送到显示端；从写指针到读指针之间的是空闲槽位，锁帮助我们维护了这些特性不变。

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)

我们接下来看一下uart.c中的uartputc函数。

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)

函数首先获得了锁，然后查看当前缓存是否还有空槽位，如果有的话将数据放置于空槽位中；写指针加1；调用uartstart；最后释放锁。

如果两个进程在同一个时间调用uartputc，那么这里的锁会确保来自于第一个进程的一个字符进入到缓存的第一个槽位，接下来第二个进程的一个字符进入到缓存的第二个槽位。这就是锁帮助我们避免race condition的一个简单例子。如果没有锁的话，第二个进程可能会覆盖第一个进程的字符。

接下来我们看一下uartstart函数，

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)

如果uart_tx_w不等于uart_tx_r，那么缓存不为空，说明需要处理缓存中的一些字符。锁确保了我们可以在下一个字符写入到缓存之前，处理完缓存中的字符，这样缓存中的数据就不会被覆盖。

最后，锁确保了一个时间只有一个CPU上的进程可以写入UART的寄存器，THR。所以这里锁确保了硬件寄存器只有一个写入者。

当UART硬件完成传输，会产生一个中断。在前面的代码中我们知道了uartstart的调用者会获得锁以确保不会有多个进程同时向THR寄存器写数据。但是UART中断本身也可能与调用printf的进程并行执行。如果一个进程调用了printf，它运行在CPU0上；CPU1处理了UART中断，那么CPU1也会调用uartstart。因为我们想要确保对于THR寄存器只有一个写入者，同时也确保传输缓存的特性不变（注，这里指的是在uartstart中对于uart_tx_r指针的更新），我们需要在中断处理函数中也获取锁。

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)

所以，在XV6中，驱动的bottom部分（注，也就是中断处理程序）和驱动的up部分（注，uartputc函数）可以完全的并行运行，所以中断处理程序也需要获取锁。我们接下来会介绍，在实现锁的时候，为了确保这里能正常工作还是有点复杂的。

（注，下面问答来自课程结束部分）

> 学生提问：UART的缓存中，读指针是不是总是会落后于写指针？
>
> Frans教授：从读指针到写指针之间的字符是要显示的字符，UART会逐次的将读指针指向的字符在显示器上显示，同时printf可能又会将新的字符写入到缓存。读指针总是会落后于写指针直到读指针追上了写指针，这时两个指针相同，并且此时缓存中没有字符需要显示。



## 自旋锁（spin lock）的实现

锁的特性是，只有一个进程能获取锁，在任何时间，锁只能有一个持有者。我们来看看这是如何实现了。

我们先看看一个有问题的锁是如何实现的。 

在acquire中，有一个while loop，判断锁对象是否为0，如果为0，说明锁当前没用持有者，对于单签acquire的调用可以获取锁，之后再将locked 字段设置为1.

问题在哪里？ 在这个while loop中的操作都不是原子操作，意味着可能会有两个进程同时在while loop中获取锁。

因此，我们需要在真正的原子操作上实现。最常见的方法是依赖于一个特殊的硬件指令，保证test-and-set操作的原子性。在RISC-V，这个特殊的指令就是amoswap（atomic memory swap），这条指令接受三个参数，address， r1， r2.，这条指令首先会锁住address，将address上的数据保存在临时变量temp中，之后将r1的数据写入地址中，之后再将保存在临时变量中的数据写入到r2中，最后对地址解锁。

最终的效果就是，r1的内容写入地址中，地址中的内容写入r2中。

通过在这里加锁，可以确保address中的数据存放于r2，而r1中的数据存放于address中。 

这里我们通过将一个软件锁转变为硬件锁最终实现了原子性。不同处理器的具体实现可能会非常不一样，处理器的指令集通常像是一个说明文档，它不会有具体实现的细节，具体的实现依赖于内存系统是如何工作的，比如说：

- 

  多个处理器共用一个内存控制器，内存控制器可以支持这里的操作，比如给一个特定的地址加锁，然后让一个处理器执行2-3个指令，然后再解锁。因为所有的处理器都需要通过这里的内存控制器完成读写，所以内存控制器可以对操作进行排序和加锁。

- 

  如果内存位于一个共享的总线上，那么需要总线控制器（bus arbiter）来支持。总线控制器需要以原子的方式执行多个内存操作。

- 

  如果处理器有缓存，那么缓存一致性协议会确保对于持有了我们想要更新的数据的cache line只有一个写入者，相应的处理器会对cache line加锁，完成两个操作。



接下来看看如何通过atomic swap来实现自旋锁。spin lock。

这是锁的定义。，

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)

在spinlock.c中，有函数acquire

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)

其中_sync_lock_test_and_set函数与我们之前描述的指令一样。这个函数也是一个while loop，判断锁状态，如果成功设置成1，就return。

再看看release函数。它也用了相同的函数，

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)



在汇编代码中就能看出它的操作基本上就是把0写入到s1中，它基本确保了将lk->locked中写入0是一个原子操作。

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)

有关spin lock有三个细节。

**第一，**

有很多同学问，为什么不直接使用store指令将锁的locked字段写为0,？

因为store操作不是原子操作，会出现竞争的情况。

第二个细节是在acquire函数最开始，中断会被关闭。

uartputc函数会acquire锁，UART本质上就是传输字符，当UART完成了字符传输它会做什么？是的，它会产生一个中断之后会运行uartintr函数，在uartintr函数中，会获取同一把锁，但是这把锁正在被uartputc持有。如果这里只有一个CPU的话，那这里就是死锁。中断处理程序uartintr函数会一直等待锁释放，但是CPU不出让给uartputc执行的话锁又不会释放。在XV6中，这样的场景会触发panic，因为同一个CPU会再次尝试acquire同一个锁。

所以spinlock需要处理两类并发，一类是不同CPU之间的并发，一类是相同CPU上中断和普通程序之间的并发。针对后一种情况，我们需要在acquire中关闭中断。中断会在release的结束位置再次打开，因为在这个位置才能再次安全的接收中断。

第三个细节就是memory ordering。假设我们先通过将locked字段设置为1来获取锁，之后对x加1，最后再将locked字段设置0来释放锁。下面将会是在CPU上执行的指令流：

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)

但是编译器或者处理器可能会重排指令以获得更好的性能。对于上面的串行指令流，如果将x<-x+1移到locked<-0之后可以吗？这会改变指令流的正确性吗？

并不会，因为x和锁完全相互独立，它们之间没有任何关联。如果他们还是按照串行的方式执行，x<-x+1移到锁之外也没有问题。所以在一个串行执行的场景下是没有问题的。实际中，处理器在执行指令时，实际指令的执行顺序可能会改变。编译器也会做类似的事情，编译器可能会在不改变执行结果的前提下，优化掉一些代码路径并进而改变指令的顺序。

但是对于并发执行，很明显这将会是一个灾难。如果我们将critical section与加锁解锁放在不同的CPU执行，将会得到完全错误的结果。所以指令重新排序在并发场景是错误的。为了禁止，或者说为了告诉编译器和硬件不要这样做，我们需要使用memory fence或者叫做synchronize指令，来确定指令的移动范围。对于synchronize指令，任何在它之前的load/store指令，都不能移动到它之后。锁的acquire和release函数都包含了synchronize指令。

![img](Lec10%20Multiprocesssors%20and%20locking%20.assets/image.png)

这样前面的例子中，x<-x+1就不会被移到特定的memory synchronization点之外。我们也就不会有memory ordering带来的问题。这就是为什么在acquire和release中都有__sync_synchronize函数的调用。

总结一下，锁能保证并行程序的正确性但是会降低性能。并且锁会带来很大的复杂性。因此不到万不得已不要共享数据。如果你不共享数据，那么就不存在race condition。 程序就不会变得复杂。 如果你真的需要用锁，先从coarse-grained lock开始，基于测试的结果优化你的lock，fine-grained lock。

最后，使用race detector来找到race condition，如果你将锁的acquire和release放置于错误的位置，那么就算使用了锁还是会有race。

